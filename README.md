# SCENet
SCENet: Secondary Domain InterCorrelation Enhanced Network for Alleviating Compressed Poisson Noises, in revision. 

# Results

### Figure 6. Comparison of the subjective visual quality for four classical images, Butterfly, Lena, Peppers, and Mobile. (a) Ground truths. (b) Degraded images with q=10 and peak=200. (c). Results of BM3D [22]. (d) Results of SSRQC [23]. (e) Results of ARCNN [2]. (f) Results of DnCNN [4]. (g) Results of MWCNN [5]. (h) Results of SCENet.
![Figure 6](https://user-images.githubusercontent.com/46806852/56005829-64e1fa00-5d0d-11e9-9cfe-0d9d84d2cc30.png)

### Figure 7. Comparison of the subjective visual quality for four images from the LIVE1 database, Caps, Womanhat, Carnivaldolls, and Lighthouse2. (a) Ground truths. (b) Degraded images with q=20 and peak=400. (c). Results of BM3D [22]. (d) Results of SSRQC [23]. (e) Results of ARCNN [2]. (f) Results of DnCNN [4]. (g) Results of MWCNN [5]. (h) Results of SCENet.
![Figure 7](https://user-images.githubusercontent.com/46806852/56005830-657a9080-5d0d-11e9-8a4c-33b13953d174.png)

### Figure 8. Comparison of the subjective visual quality for the image from the SIDD dataset, Books. (a) Captured image using iphone7 with ISO=800 and exposure=1/2000 (BRISQUE=43.36). (b) JPEG-coded image with q=30 (BRISQUE=41.97). (c) Result of BM3D [22] (BRISQUE=45.06). (d) Result of SSRQC [23] (BRISQUE=37.01). (e) Result of ARCNN [2] (BRISQUE=33.15). (f) Result of DnCNN [4] (BRISQUE=33.09). (g) Result of MWCNN [5] (BRISQUE=37.65). (h) Result of SCENet (BRISQUE=25.55).
![Figure 8](https://user-images.githubusercontent.com/46806852/56005832-657a9080-5d0d-11e9-94d1-c4ed4a8432b6.png)

### Figure 9. Comparison of the subjective visual quality for the image from the SIDD dataset, Desk. (a) Captured image using iphone7 with ISO=200 and exposure=1/400 (BRISQUE=46.81). (b) JPEG-coded image with q=30 (BRISQUE=28.98). (c) Result of BM3D [22] (BRISQUE=22.20). (d) Result of SSRQC [23] (BRISQUE=26.07). (e) Result of ARCNN [2] (BRISQUE=24.35). (f) Result of DnCNN [4] (BRISQUE=21.78). (g) Result of MWCNN [5] (BRISQUE=24.11). (h) Result of SCENet (BRISQUE=19.70).
![Figure 9](https://user-images.githubusercontent.com/46806852/56005834-657a9080-5d0d-11e9-9c2e-93c038baf1cd.png)

### Table 2. Comparison of the objective quality on the LIVE1 database in terms of average PSNR (dB) and SSIM.
![Table 2](https://user-images.githubusercontent.com/46806852/56005836-66132700-5d0d-11e9-8386-3ce1ff6a5ed0.png)


# References

2.	Dong, C.; Deng, Y.; Change L.C.; Tang, X. (2015). Compression artifacts reduction by a deep convolutional network. In Proceedings of the IEEE International Conference on Computer Vision, Santiago, Chile, 11–18 December 2015; pp. 576–584.
4.	Zhang, K.; Zuo, W.; Chen, Y.; Meng, D.; Zhang, L. Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising. IEEE Trans. Image Process. 2017, 26, 3142–3155. 
5.	Liu, P.; Zhang, H.; Zhang, K.; Lin, L.; Zuo, W. Multi-level wavelet-CNN for image restoration. In Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, Salt Lake City, USA, 18–22 June 2018, pp. 773–782.
22.	Dabov, K.; Foi, A.; Katkovnik, V.; Egiazarian, K. Image denoising by sparse 3-D transform-domain collaborative filtering. IEEE Trans. Image Process. 2007, 16, 2080–2095.
23.	Zhao, C.; Zhang, J.; Ma, S.; Fan, X.; Zhang, Y.; Gao, W. Reducing image compression artifacts by structural sparse representation and quantization constraint prior. IEEE Trans. Circuits Sys. Video Technol. 2017, 27, 2057–2071.
